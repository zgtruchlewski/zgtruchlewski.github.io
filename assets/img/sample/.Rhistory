cmdstan=TRUE , threads=2 , refresh=1000 )
toc()
tic()
m1 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat , chains=4 , cores=4 ,
cmdstan=TRUE , threads=2 , refresh=1000 )
toc()
tic()
m1 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat , refresh=1000 )
toc()
tic()
m0 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat  )
toc()
# two threads:
# base rethinking: 60.399 sec elapsed
tic()
m4 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat ,
chains=4 , cores=4 ,refresh=1000 )
toc()
# just cmdstan, no threads: 24.112 sec elapsed
tic()
m5 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat , chains=4 , cores=4 ,
cmdstan=TRUE , refresh=1000 )
toc()
tic()
m6 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat , chains=4 , cores=4 ,
cmdstan=TRUE , threads=2 , refresh=1000 )
toc()
View(dat)
tic()
m3 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat ,
cmdstan=TRUE , threads=2 , refresh=1000 )
t_m3 <- toc()
t_m3
tic()
m3 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat ,
cmdstan=TRUE , threads=2 )
toc()
N <- 1e5
x <- rnorm(N)
m <- 1 + rpois(N,2)
y <- rbinom( N , size=m , prob=inv_logit(-3+x) )
dat <- list( y=y , x=x , m=m )
# normal: 49.465 sec elapsed
tic()
m0 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat  )
toc()
# base rethinking: 60.399 sec elapsed
tic()
m1 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat , refresh=1000 )
toc()
# just cmdstan, no threads: 24.112 sec elapsed
tic()
m2 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat ,
cmdstan=TRUE , refresh=1000 )
toc()
# two threads: 18.407 sec elapsed
tic()
m3 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat ,
cmdstan=TRUE , threads=2 )
toc()
N <- 1e6
x <- rnorm(N)
m <- 1 + rpois(N,2)
y <- rbinom( N , size=m , prob=inv_logit(-3+x) )
dat <- list( y=y , x=x , m=m )
# normal: 49.465 sec elapsed
tic()
m0 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat  )
toc()
# base rethinking: 60.399 sec elapsed
tic()
m1 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat , refresh=1000 )
toc()
# just cmdstan, no threads: 24.112 sec elapsed
tic()
m2 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat ,
cmdstan=TRUE , refresh=1000 )
toc()
# two threads: 18.407 sec elapsed
tic()
m3 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat ,
cmdstan=TRUE , threads=2 )
toc()
N <- 1e6
x <- rnorm(N)
m <- 1 + rpois(N,2)
y <- rbinom( N , size=m , prob=inv_logit(-3+x) )
dat <- list( y=y , x=x , m=m )
# normal: 49.465 sec elapsed
tic()
m0 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat  )
toc()
# base rethinking: 60.399 sec elapsed
tic()
m1 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat , refresh=1000 )
toc()
# just cmdstan, no threads: 24.112 sec elapsed
tic()
m2 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat ,
cmdstan=TRUE , refresh=1000 )
toc()
# two threads: 18.407 sec elapsed
tic()
m3 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat ,
cmdstan=TRUE , threads=2 )
toc()
tic()
m3 <- ulam(alist(
y ~ binomial_logit( m , logit_p ),
logit_p <- a + b*x,
a ~ normal(0,1.5),
b ~ normal(0,0.5)
) , data=dat ,
cmdstan=TRUE , threads=2 )
toc()
q()
library(rethinking)
data(reedfrogs)
d <- reedfrogs
dat <- list(S = d$surv,
n = d$density,
tank = 1:nrow(d),
pred = ifelse( d$pred=="no" , 0L , 1L ),
size_ = ifelse( d$size=="small" , 1L , 2L )
)
m1.2 <- ulam(alist(
S ~ binomial( n , p ),
logit(p) <- a[tank],
a[tank] ~ normal( a_bar , sigma ),
a_bar ~ normal( 0 , 1.5 ),
sigma ~ exponential( 1 )),
data=dat , chains=4 , cores=4 , log_lik=TRUE , cmdstan=TRUE ) # , cmdstan=TRUE
# pred
m1.2 <- ulam(alist(
S ~ binomial( n , p ),
logit(p) <- a[tank] + bp*pred,
a[tank] ~ normal( a_bar , sigma ),
bp ~ normal( -0.5 , 1 ),
a_bar ~ normal( 0 , 1.5 ),
sigma ~ exponential( 1 )),
data=dat , chains=4 , cores=4 , log_lik=TRUE )# size | , cmdstan=TRUE
m1.2 <- map2stan(alist(
S ~ binomial( n , p ),
logit(p) <- a[tank],
a[tank] ~ normal( a_bar , sigma ),
a_bar ~ normal( 0 , 1.5 ),
sigma ~ exponential( 1 )),
data=dat , chains=4 , cores=4 , log_lik=TRUE , cmdstan=TRUE )
library(rethinking)
data(islandsDistMatrix)
# display short column names, so fits on screen
Dmat <- islandsDistMatrix
colnames(Dmat) <- c("Ml","Ti","SC","Ya","Fi","Tr","Ch","Mn","To","Ha")
round(Dmat,1)
## R code 13.30
# linear
curve( exp(-1*x) , from=0 , to=4 , lty=2 ,
xlab="distance" , ylab="correlation" )
# squared
curve( exp(-1*x^2) , add=TRUE )
## R code 13.31
data(Kline2) # load the ordinary data, now with coordinates
d <- Kline2
d$society <- 1:10 # index observations
m13.7 <- ulam(
alist(
total_tools ~ dpois(lambda),
log(lambda) <- a + g[society] + bp*logpop,
g[society] ~ GPL2( Dmat , etasq , rhosq , 0.01 ),
a ~ dnorm(0,10),
bp ~ dnorm(0,1),
etasq ~ dcauchy(0,1),
rhosq ~ dcauchy(0,1)
),
data=list(
total_tools=d$total_tools,
logpop=d$logpop,
society=d$society,
Dmat=islandsDistMatrix),
warmup=2000 , iter=1e4 , chains=4 )
install.packages("manifestoR")
library(manifestoR)
library(brms)
set.seed(54647)
# number of observations
N <- 1E4
# number of group levels
G <- round(N / 10)
# number of predictors
P <- 3
# regression coefficients
beta <- rnorm(P)
# sampled covariates, group means and fake data
fake <- matrix(rnorm(N * P), ncol = P)
dimnames(fake) <- list(NULL, paste0("x", 1:P))
# fixed effect part and sampled group membership
fake <- transform(
as.data.frame(fake),
theta = fake %*% beta,
g = sample.int(G, N, replace=TRUE)
)
# add random intercept by group
fake  <- merge(fake, data.frame(g = 1:G, eta = rnorm(G)), by = "g")
# linear predictor
fake  <- transform(fake, mu = theta + eta)
# sample Poisson data
fake  <- transform(fake, y = rpois(N, exp(mu)))
# shuffle order of data rows to ensure even distribution of computational effort
fake <- fake[sample.int(N, N),]
# drop not needed row names
rownames(fake) <- NULL
model_poisson <- brm(
y ~ 1 + x1 + x2 + (1 | g),
data = fake,
family = poisson(),
iter = 500, # short sampling to speedup example
chains = 2,
prior = prior(normal(0,1), class = b) +
prior(constant(1), class = sd, group = g),
backend = "cmdstanr",
threads = threading(4)
)
q()
library(car)
library(dotwhisker)
library(forward)
library(MASS)
library(stargazer)
library(tikzDevice)
install.packages("forward")
install.packages("dotwhisker")
library(car)
library(dotwhisker)
library(forward)
library(MASS)
library(stargazer)
library(tikzDevice)
install.packages("tikzDevice")
set.seed(20)
x1 = rnorm(20, mean=20, sd=3)
y1 = 5 + .5*x1 + rnorm(20)
x2 = c(x1, 30);        y2 = c(y1, 20.8)
x3 = c(x1, 19.44);     y3 = c(y1, 20.8)
x4 = c(x1, 30);        y4 = c(y1, 10)
par(bty="n" , mar=c(2,2,1,0.5), mfrow=c(1,2))
reg1 <- lm(y1 ~ x1)
plot(x1, y1, col=ifelse(x1==20.08467, "red", "black"))
abline(reg1)
plot(reg1, 5)
influencePlot(reg1)
reg1 <- lm(prestige ~ education + income, data= Duncan)
summary(reg1)
influenceIndexPlot(reg1, bty="n")
influencePlot(reg1, bty="n", ylim=c(-3,3.5))
q()
library(ndtv)
install.packages("ndtv")
library(ndtv)
data(short.stergm.sim)
proximity.timeline(short.stergm.sim,default.dist = 6,
mode = 'sammon',labels.at = 17,vertex.cex = 4)
View(short.stergm.sim)
net.sym <- as.undirected(net, mode = "collapse",
edge.attr.comb = list(weight = "sum", "ignore"))
# Rewiring
net.sym.rewired <- rewire(net.sym, each_edge(prob = 0.1))
net.sym.rewired
plot(net.sym.rewired, vertex.size = 10, vertex.label = NA)
q()
install.packages("languageserver")
q()
# dev.off()
rm(list = ls())
setwd("/Users/zbigniewtruchlewski/Dropbox/PhD/Publications/ToPublish/GeographyAusterity")
# Load libraries
library(Cairo)
library(dplyr)
library(foreign)
library(ggmap)
library(ggplot2)
library(haven)
library(Imap)
library(maps)
library(pheatmap)
library(RColorBrewer)
library(readstata13)
library(reshape2)
library(rethinking)
library(stargazer)
library(tibble)
library(tictoc)
library(tile)
library(xtable)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
options(digits=2)
set.seed(123456)
my.col<-brewer.pal(n=3, name="Dark2")
my.col2<-brewer.pal(n=3, name="Set2")
# Stata data
GP <- read.dta13("Data/GP.dta")
# R data
# load("Data/GP.RData")
# Prepare clean data matrix without missing data
# But say how much missing data there is?
GPtrim <- GP[ , c("cntry", "countryn", "year", "yearid", "alefull_tot",
"alefull_tax", "alefull_spend", "tot_dum", "tax_dum", "spend_dum",
"debt", "deficit", "gdpgr", "eu", "emu", "latam") ]
GPcc <- GPtrim[ complete.cases(GPtrim) , ]
# Standardize predictors
GPcc$debts <- round(scale( GPcc$debt ), 2)
GPcc$deficits <- round(scale( GPcc$deficit ), 2)
GPcc$gdpgrs <- round(scale( GPcc$gdpgr ), 2)
# LAG THE THREE PREDICTORS!
# DESCRIPTIVES: how many episodes of what?
GPcc$tax_dum <- as.numeric(GPcc$alefull_tax > GPcc$alefull_spend)
GPcc$spend_dum <- as.numeric(GPcc$alefull_tax < GPcc$alefull_spend)
sum(GPcc$tot_dum) # 342 austerity episodes
sum(GPcc$tax_dum) # 138 tax hikes
sum(GPcc$spend_dum) # 201 spending cuts
# Per McElreath 2016, mean and variance are almost the same, so we can use Poisson
c( mean(GPcc$tot_dum) , var(GPcc$tot_dum) )
c( mean(GPcc$tax_dum) , var(GPcc$tax_dum) )
c( mean(GPcc$spend_dum) , var(GPcc$spend_dum) )
# Upload all Distance matrices
load("Data/CoordinatesDistMats/coordinates.RData")
load("Data/CoordinatesDistMats/dist_mat_ALL.RData")
load("Data/CoordinatesDistMats/coordinates_ALL.RData")
load("Data/CoordinatesDistMats/dist_mat_ALL.RData")
load("Data/CoordinatesDistMats/INVdist_mat_ALL.RData")
load("Data/CoordinatesDistMats/distradew.RData")
tic()
GP_tot_dum_DISTRADE <- ulam(alist(
tot_dum ~ dbinom( 1 , p ),
logit(p) <- a + a_country[countryn] + a_year[yearid] + Debt*debts + Deficit*deficits + GDP*gdpgrs + EMU*emu,
# non-centered Gaussian Process prior
transpars> vector[31]: a_country <<- L_SIGMA * z,
vector[31]: z ~ normal( 0 , 1 ),
transpars> matrix[31,31]: L_SIGMA <<- cholesky_decompose( SIGMA ),
transpars> matrix[31,31]: SIGMA <- cov_GPL2( dist_mat, etasq, rhosq, sigmasq ),
a_year[yearid] ~ dnorm( 0 , sigma_year ),
a ~ dnorm(0,10),
c(Debt,Deficit,GDP,EMU) ~ dnorm(0,1),
sigma ~ dcauchy(0,2),
c(etasq,rhosq,sigmasq) ~ dcauchy(0,1),
sigma_year ~ dcauchy(0,1)
), data=list(
tot_dum=GPcc$tot_dum,
countryn=GPcc$countryn,
yearid=GPcc$yearid,
debts=GPcc$debts,
deficits=GPcc$deficits,
gdpgrs=GPcc$gdpgrs,
emu=GPcc$emu,
dist_mat=distradew),
warmup=2000, iter=1e4, cores=1, chains=1,
control=list(adapt_delta=0.9999), cmdstan=TRUE)
toc()
precis(GP_tot_dum_DISTRADE)
# install rethinking library with instructions here:
# https://github.com/rmcelreath/statrethinking_winter2019
library(rethinking)
library(dagitty)
library(shape)
# the structural model
# W: wages
# Q: quarter of year of birth
# E: education
# U: unobserved confound
the_dag <- dagitty("dag{
Q -> E -> W
E <- U -> W
}")
coordinates(the_dag) <- list(x=c(Q=0,E=1,W=2,U=1.5),y=c(U=0,Q=1,E=1,W=1))
drawdag(the_dag)
# find instruments
instrumentalVariables( the_dag , exposure="E" , outcome="W" )
library(dagitty)
dag_6.1 <- dagitty( "dag {
U [unobserved]
X -> Y
X <- U <- A -> C -> Y U -> B <- C
}")
adjustmentSets( dag_6.1 , exposure="X" , outcome="Y" )
drawdag(dag_6.1)
DAG <- dagitty( "dag{ Directed -> Acyclic; Acyclic -> Graph; Graph -> Inference; Directed -> Causal ; Causal -> Inference }" )
drawdag(DAG)
coordinates(DAG) <- list( x=c(Directed=0, Acyclic=1, Graph=2, Causal=0,Inference=2) , y=c(Directed=0, Acyclic=1, Graph=0, Causal=2,Inference=2) )
drawdag(DAG)
coordinates(DAG) <- list( x=c(Directed=0, Acyclic=.5, Graph=2, Causal=0,Inference=2) , y=c(Directed=0, Acyclic=.5, Graph=0, Causal=2,Inference=2) )
drawdag(DAG)
coordinates(DAG) <- list( x=c(Directed=0, Acyclic=.5, Graph=1, Causal=0,Inference=1) , y=c(Directed=0, Acyclic=.5, Graph=0, Causal=1,Inference=1) )
drawdag(DAG)
library(Cairo)
setwd("/Users/zbigniewtruchlewski/Dropbox (Personal)/GitHub/zgtruchlewski.github.io/assets/img/sample")
cairo_pdf("DAG.pdf" ,width=3,height=1.5, bg="transparent", family = "Gill Sans MT")
par(mar = c(2.75, 2.75, 2, .25), mgp = c(1.5, .5, 0), oma = c(0.2, 0, 0, 0), col.lab = "black")
drawdag(DAG)
dev.off()
g <- getExample("Shrier")
plot(g)
drawdag(the_dag)
# find instruments
instrumentalVariables( the_dag , exposure="E" , outcome="W" )
library(dagitty)
DAG <- dagitty( "dag{ Directed -> Acyclic; Acyclic -> Graph; Graph -> Inference; Directed -> Causal; Causal -> Inference }" )
coordinates(DAG) <- list( x=c(Directed=0, Acyclic=1, Graph=2, Causal=0,Inference=2) , y=c(Directed=0, Acyclic=1, Graph=0, Causal=2,Inference=2) )
drawdag(DAG)
cairo_pdf("DAG.pdf" ,width=3,height=1.5, bg="transparent", family = "Gill Sans MT")
par(mar = c(2.75, 2.75, 2, .25), mgp = c(1.5, .5, 0), oma = c(0.2, 0, 0, 0), col.lab = "black")
drawdag(DAG)
dev.off()
